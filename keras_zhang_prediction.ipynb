{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D,MaxPooling2D,UpSampling2D,Input,BatchNormalization,LeakyReLU,Conv2DTranspose,Dense,Softmax\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow import set_random_seed\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR') # Filter out annoying WARNING deprecated method logs\n",
    "\n",
    "set_random_seed(123)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "#global graph\n",
    "graph = tf.get_default_graph()\n",
    "sess = tf.Session(graph=graph, config=session_conf)\n",
    "\n",
    "#gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.9)\n",
    "#sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=8, inter_op_parallelism_threads=8, gpu_options=gpu_options))\n",
    "\n",
    "\n",
    "\n",
    "tf.keras.backend.set_session(sess)\n",
    "set_random_seed(2)\n",
    "np.random.seed(1)\n",
    "\n",
    "#print(os.listdir(\"input/dataset/dataset_updated/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import sklearn.neighbors as nn\n",
    "import random\n",
    "channel = 3\n",
    "epsilon = 1e-8\n",
    "T = 0.38\n",
    "img_rows=256\n",
    "img_cols =256\n",
    "nb_neighbors = 5\n",
    "\n",
    "h, w = img_rows // 4, img_cols // 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the array of quantized ab value\n",
    "q_ab = np.load(\"npy/pts_in_hull.npy\")\n",
    "nb_q = q_ab.shape[0]\n",
    "\n",
    "# Fit a NN to q_ab\n",
    "nn_finder = nn.NearestNeighbors(n_neighbors=nb_neighbors, algorithm='ball_tree').fit(q_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "modelT = keras.models.load_model('final_models/keras_zhang_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder_pred = 'data/'\n",
    "img_names_pred=os.listdir(image_folder_pred)\n",
    "pred_names = [f for f in img_names_pred if f.lower().endswith('.jpeg')]\n",
    "\n",
    "names_file = 'prediction_names.txt'\n",
    "with open(names_file, 'w') as file:\n",
    "    file.write('\\n'.join(pred_names))\n",
    "\n",
    "with open(names_file, 'r') as f:\n",
    "    names = f.read().splitlines()\n",
    "print(len(names))\n",
    "samples = random.sample(names, 10)\n",
    "\n",
    "#https://stackoverflow.com/a/50941282\n",
    "#with graph.as_default():\n",
    "for i in range(len(samples)):\n",
    "    image_name = samples[i]\n",
    "    filename = os.path.join(image_folder_pred, image_name)\n",
    "    print('filename', filename)\n",
    "    # b: 0 <=b<=255, g: 0 <=g<=255, r: 0 <=r<=255.\n",
    "    bgr = cv2.imread(filename)\n",
    "    if bgr is None:\n",
    "        continue\n",
    "\n",
    "    print('Start processing image: {}'.format(filename))\n",
    "    gray = cv2.imread(filename, 0)\n",
    "    bgr = cv2.resize(bgr, (img_rows, img_cols), cv2.INTER_CUBIC)\n",
    "    gray = cv2.resize(gray, (img_rows, img_cols), cv2.INTER_CUBIC)\n",
    "    # L: 0 <=L<= 255, a: 42 <=a<= 226, b: 20 <=b<= 223.\n",
    "    lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)\n",
    "    L = lab[:, :, 0]\n",
    "    a = lab[:, :, 1]\n",
    "    b = lab[:, :, 2]\n",
    "    # print('np.max(L): ' + str(np.max(L)))\n",
    "    # print('np.min(L): ' + str(np.min(L)))\n",
    "    # print('np.max(a): ' + str(np.max(a)))\n",
    "    # print('np.min(a): ' + str(np.min(a)))\n",
    "    # print('np.max(b): ' + str(np.max(b)))\n",
    "    # print('np.min(b): ' + str(np.min(b)))\n",
    "    x_test = np.empty((1, img_rows, img_cols, 1), dtype=np.float32)\n",
    "    x_test[0, :, :, 0] = gray / 255.\n",
    "\n",
    "    # L: 0 <=L<= 255, a: 42 <=a<= 226, b: 20 <=b<= 223.\n",
    "    X_colorized = modelT.predict(x_test)\n",
    "    #K.clear_session()\n",
    "    X_colorized = X_colorized.reshape((h * w, nb_q))\n",
    "\n",
    "    # Reweight probas\n",
    "    X_colorized = np.exp(np.log(X_colorized + epsilon) / T)\n",
    "    X_colorized = X_colorized / np.sum(X_colorized, 1)[:, np.newaxis]\n",
    "\n",
    "    # Reweighted\n",
    "    q_a = q_ab[:, 0].reshape((1, 313))\n",
    "    q_b = q_ab[:, 1].reshape((1, 313))\n",
    "\n",
    "    X_a = np.sum(X_colorized * q_a, 1).reshape((h, w))\n",
    "    X_b = np.sum(X_colorized * q_b, 1).reshape((h, w))\n",
    "    # print('np.max(X_a): ' + str(np.max(X_a)))\n",
    "    # print('np.min(X_a): ' + str(np.min(X_a)))\n",
    "    # print('np.max(X_b): ' + str(np.max(X_b)))\n",
    "    # print('np.min(X_b): ' + str(np.min(X_b)))\n",
    "    X_a = cv2.resize(X_a, (img_rows, img_cols), cv2.INTER_CUBIC)\n",
    "    X_b = cv2.resize(X_b, (img_rows, img_cols), cv2.INTER_CUBIC)\n",
    "\n",
    "    # Before: -90 <=a<= 100, -110 <=b<= 110\n",
    "    # After: 38 <=a<= 228, 18 <=b<= 238\n",
    "    X_a = X_a + 128\n",
    "    X_b = X_b + 128\n",
    "    # print('np.max(X_a): ' + str(np.max(X_a)))\n",
    "    # print('np.min(X_a): ' + str(np.min(X_a)))\n",
    "    # print('np.max(X_b): ' + str(np.max(X_b)))\n",
    "    # print('np.min(X_b): ' + str(np.min(X_b)))\n",
    "\n",
    "    out_lab = np.zeros((img_rows, img_cols, 3), dtype=np.int32)\n",
    "    out_lab[:, :, 0] = lab[:, :, 0]\n",
    "    out_lab[:, :, 1] = X_a\n",
    "    out_lab[:, :, 2] = X_b\n",
    "    out_L = out_lab[:, :, 0]\n",
    "    out_a = out_lab[:, :, 1]\n",
    "    out_b = out_lab[:, :, 2]\n",
    "    # print('np.max(out_L): ' + str(np.max(out_L)))\n",
    "    # print('np.min(out_L): ' + str(np.min(out_L)))\n",
    "    # print('np.max(out_a): ' + str(np.max(out_a)))\n",
    "    # print('np.min(out_a): ' + str(np.min(out_a)))\n",
    "    # print('np.max(out_b): ' + str(np.max(out_b)))\n",
    "    # print('np.min(out_b): ' + str(np.min(out_b)))\n",
    "    out_lab = out_lab.astype(np.uint8)\n",
    "    out_bgr = cv2.cvtColor(out_lab, cv2.COLOR_LAB2BGR)\n",
    "    # print('np.max(out_bgr): ' + str(np.max(out_bgr)))\n",
    "    # print('np.min(out_bgr): ' + str(np.min(out_bgr)))\n",
    "    out_bgr = out_bgr.astype(np.uint8)\n",
    "\n",
    "    if not os.path.exists('images'):\n",
    "        os.makedirs('images')\n",
    "\n",
    "    cv2.imwrite('images/{}_image.png'.format(i), gray)\n",
    "    cv2.imwrite('images/{}_gt.png'.format(i), bgr)\n",
    "    cv2.imwrite('images/{}_out.png'.format(i), out_bgr)\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
